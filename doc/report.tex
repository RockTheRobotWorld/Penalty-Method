\documentclass{iopart}
\input{myhead}

\begin{document}

\title[A penalty method for PDE-constrained optimization]{A penalty method for PDE-constrained optimization}
\author{Tristan van Leeuwen$^1$ and Felix J. Herrmann$^2$}
\address{$^1$Centrum Wiskunde \& Informatica. Science Park, Amsterdam, the Netherlands\\
$^2$ Dept. of Earth, Ocean and Atmospheric Sciences.\\2207 Main Mall, Vancouver, BC Canada V6T 1Z4.}
\ead{tleeuwen@eos.ubc.ca}

\begin{abstract}
We present a method for solving PDE constrained optimization problems
based on a penalty formulation. This method aims to combine advantages
of both full-space and reduced methods by exploiting a large
search-space (consisting of both control and state variables) while
allowing for an efficient implementation that avoids storing and
updating the state-variables. This leads to a method that has roughly
the same per-iteration complexity as conventional reduced approaches
while defining an objective that is less non-linear in the control
variable by implicitly relaxing the constraint. We apply the method to a
seismic inverse problem where it leads to a particularly efficient
implementation when compared to a conventional reduced approach as it
avoids the use of adjoint state-variables. Numerical examples illustrate
the approach and suggest that the proposed formulation can indeed
mitigate some of the well-known problems with local minima in the
seismic inverse problem.
\end{abstract}

\maketitle

\section{Introduction}
In parameter estimation, the goal is to infer physical parameters (e.g., density, soundspeed or conductivity) 
from partial measurements of solutions of a PDE that describes the physical process as a 
function of the paramater of interest (e.g., a wave-equation, ). These problems arise in many applications such as
geophysics \cite{Haber2004,Epanomeritakis08}, medical imaging \cite{Abdoulaev2005} and non-destructive testing.

For linear PDEs, the resulting optimzation problem (after discretization) can be written as
\bq
\label{eq:constr}
\min_{\mbf{m},\mbf{u}} \ts{\frac{1}{2}}||P^T\mathbf{u} - \mathbf{d}||_2^2 \quad 
\mbox{s.t.} \quad A(\mathbf{m})\mathbf{u} = \mathbf{q},
\eq
where $\mathbf{m}$ is the (gridded) parameter of interest, $\mathbf{u}$ is the field and $\mathbf{d}$ are
the input data. The measurement process is modelled by taking inner products of the field with the columns of $P$. 
The matrix $A(\mathbf{m})\mathbf{u} = \mathbf{q}$ represents the discretized PDE and $\mbf{q}$ is the 
source function. 

Oftentimes, measurements are made from multiple independent experiments, 
in which case $\mathbf{u}$ is a block vector containing the fields for different experiments. 
For some applications, such as seismic inversion, $\mbf{m}$ may represent up to $\mcl{O}(10^9)$ unknowns 
while $\mbf{u}$ may easily represent $\mcl{O}(10^{17})$.

\subsection{All-at-once approach}
A popular approach to solving
these constrained problems is based on the corresponding Lagrangian:
\bq
\mcl{L}(\mbf{m},\mbf{u},\mbf{v})=  \ts{\frac{1}{2}}||P^T\mathbf{u} - \mathbf{d}||_2^2 
+ \mbf{v}^T\left(A(\mathbf{m})\mathbf{u} - \mathbf{q}\right),
\eq
where $^T$ denotes the (complex-conjugate) transpose.
A necessary condition for a solution to the constrained problem (\ref{eq:constr}) is that 
it is a stationary point of the Lagrangian. 
Such a stationary point may be found using a Newton-like method by repeatedly solving
the KKT system \cite{Haber2000}
\bq
\left(
\begin{array}{ccc}
R&K^T&G^T\\
K&PP^T&A^T\\
G&A&\\
\end{array}
\right)
\left(
\begin{array}{c}
\delta \mbf{m}\\
\delta \mbf{u}\\
\delta \mbf{v}\\
\end{array}
\right)=
-\left(
\begin{array}{c}
\mcl{L}_{\mbf{m}}\\
\mcl{L}_{\mbf{u}}\\
\mcl{L}_{\mbf{v}}\\
\end{array}
\right),
\eq
where
\bq
\mcl{L}_{\mbf{m}} &=& G(\mbf{m},\mbf{u})^T\mathbf{v},\\
\mcl{L}_{\mbf{u}} &=& A(\mathbf{m})^T\mathbf{v} + P(P^T\mathbf{u} - \mathbf{d}),\\
\mcl{L}_{\mbf{v}} &=& A(\mathbf{m})\mathbf{u} - \mathbf{q},\\
\eq
and
\bq
G(\mbf{m},\mbf{u}) &=& \frac{\partial A(\mbf{m})\mbf{u}}{\partial \mbf{m}},\\
K(\mbf{m},\mbf{v}) &=& \frac{\partial A(\mbf{m})^T\mbf{v}}{\partial \mbf{m}},\\
R(\mbf{m},\mbf{u},\mbf{v}) &=& \frac{\partial G(\mbf{m},\mbf{u})^T\mbf{v}}{\partial \mbf{m}}.
\eq
These Jacobian matrices are typically sparse and can be computed analytically.

An advantages of such an `all-at-once' approach are that it eliminates the need to
solve the PDEs explicitly. However, this approach is often unfeasible
for large-scale applications we have in mind because it involves simultaneously updating
(and hence storing) all the variables (up to $\mcl{O}(10^{17})$). 

\subsection{Reduced approach}
For large-scale applications, one usually considers a \emph{reduced} problem
\bq
\min_{\mbf{m}}\phi(\mbf{m}) = \ts{\frac{1}{2}}||P^T\mbf{u}(\mbf{m}) - \mbf{d}||_2^2,
\label{eq:redL}
\eq
where $\mbf{u}(\mbf{m}) = A(\mathbf{m})^{-1}\mathbf{q}$.
The resulting optimization problem has a much smaller dimension and can be solved using black-box 
non-linear optimization methods. The gradient and the (Gauss-Newton) Hessian of 
$\phi$ are given by

\bq
\nabla\phi(\mbf{m}) &=& G(\mbf{m},\mbf{u})^T\mbf{v},\\
\nabla^2\phi(\mbf{m}) &=& G(\mbf{m},\mbf{u})^TA(\mbf{m})^{-T}PP^TA(\mbf{m})^{-1}G(\mbf{m},\mbf{u})\nonumber\\
&& + K(\mbf{m},\mbf{v})^TA(\mbf{m})^{-T}G(\mbf{m},\mbf{u}) + G(\mbf{m},\mbf{u})^TA(\mbf{m})^{-T}K(\mbf{m},\mbf{v})\nonumber\\
&& + R(\mbf{m},\mbf{u},\mbf{v}).
\eq
where $\mbf{v} = A(\mbf{m})^{-T}P\left(\mbf{d} - P^T\mbf{u}\right)$.

The basic (Gauss-Newton) algorithm for minimizing $\phi(\mathbf{m})$ is given in 
Algorithm \ref{alg:reduced}.
\begin{algorithm}
\caption{Basic Gauss-Newton algorithm for find a stationary point of the Lagrangian via the reduced method}
\label{alg:reduced}
\begin{algorithmic}
\REQUIRE{initial guess $\mbf{m}^0$, tolerance $\epsilon$}
\STATE{$k=0$}
\REPEAT
\STATE{$\mathbf{u}^k_{\mathrm{red}}  = A(\mathbf{m}^k)^{-1}\mathbf{q}$}
\STATE{$\mathbf{v}^k_{\mathrm{red}}  = A(\mathbf{m}^k)^{-T}P(\mathbf{d} - P^T\mathbf{u}^k_{\mathrm{red}})$}
\STATE{$\mathbf{g}^k_{\mathrm{red}}    = G(\mathbf{m}^k,\mathbf{u}^k_{\mathrm{red}})^T\mathbf{v}^k_{\mathrm{red}}$}
\STATE{$H^k_{\mathrm{red}} = G(\mbf{m}^k,\mbf{u}^k_{\mathrm{red}})^TA(\mbf{m}^k)^{-T}PP^TA(\mbf{m}^k)^{-1}G(\mbf{m}^k,\mbf{u}^k_{\mathrm{red}})$}
\STATE{$\mathbf{m}^{k+1} =\mathbf{m}^k - \alpha^k \left(H_{\mathrm{red}}^{k}\right)^{-1}\mathbf{g}^k_{\mathrm{red}}$}
\UNTIL{$\|\mbf{g}_{\mathrm{red}} ^k\|_2 \leq \epsilon$}
\end{algorithmic}
\end{algorithm}
Note that this corresponds to a block-elimination of the KKT system and the iterates automatically
satisfy $\mcl{L}_{\mathbf{u}}(\mbf{m}^k,\mbf{u}^k_{\mathrm{red}},\mbf{v}^k_{\mathrm{red}}) = \mcl{L}_{\mathbf{v}}(\mbf{m}^k,\mbf{u}^k_{\mathrm{red}},\mbf{v}^k_{\mathrm{red}}) = 0$. 
If the algorithm terminates successfully, the final iterates additionally satisfy
$\|\mcl{L}_{\mathbf{m}}(\mbf{m}^*,\mbf{u}^*_{\mathrm{red}},\mbf{v}^*_{\mathrm{red}})\|_2^2 \leq \epsilon$.

The disadvantage of this approach is that it
requires the solution of the PDEs at each update, making it computationally very expensive. 
It also strictly enforces the constraint at each iteration, which might lead to a very
nonlinear problem in $\mbf{m}$. Moreover, the corresponding Hessian is typically a
dense matrix that cannot be stored and computing its action involves additional
PDE solves. Practical approaches are usually based on Quasi-Newton approximations of
the reduced Hessian.

\subsection{Contributions and outline}
In this paper we present an alternative to the reduced approach which
has a roughly equivalent per-iteration complexity in terms of PDE solves
and storage but retains some of the characteristics of the all-at-once
approach in the sense that it exploits a larger search space by not
enforcing the constraints at each iteration.

The approach is based on a \emph{penalty} formulation of the constrained problem,
the solution of which coincides with that of the constrained problem (\ref{eq:constr}) for an. 
appropriate choice of the penalty parameter.
Such a reformulations of the constrained problem are well-known, 
but for the sake of completeness we give a brief overview in section \ref{penalty}. The main contribution
of this paper is a solution strategy, which is based on the elimination of the state variable $u$ via
a \emph{variational projection} approach as detailed in section \ref{varpro}. The benefit of this approach is
that it effectively eliminates these variables from the optizatiom problem and thus greatly reduces the dimensionality
of the optimization problem. Due to the special structure of the problems under consideration, this elimination 
can be done efficiently, leading to a tractable algorith for large-scale problems. 
Contrary to the conventional \emph{reduced} approach, the resulting algorihtm does \emph{not} enforce the constraint
at each iteration and arguably leads to a less non-linear problem in $\mbf{m}$. It is outside the scope of the current
paper to give a rigorous prove of this statement, but a case-study presented in section
 \ref{examples} provides some numerical evidence.

A detailed description of the proposed algorihtm is given in section \ref{algorithm}.
Here, we also compare the penalty approach to both the all-at-once and the
reduced approaches in terms of algorithmic complexity.

Numerical
examples on seismic inversion using both the penalty and reduced
formulations are given in section \ref{examples}.

Possible extensions and open problems are discussed in section
\ref{discussion} and section \ref{conclusion} gives the conclusions.

\subsection{Related work}
The proposed method is related to the \emph{equation-error} approach,
which is typically used to identify the control variable in diffusion
problems given a \emph{complete} measurement of the state: $\mbf{d} = \mbf{u}$ by
solving $A(\mbf{m})\mbf{u} = \mbf{q}$ for $\mbf{m}$ \cite{Richter1981,Banerjee2013}. 
Given \emph{partial} measurements of the state $\mbf{d} = P^T\mbf{u}$, the proposed method can be seen as a
way of bootstrapping this by first attempting to reconstruct the complete
state from the partial measurements. 

\section{Penalty methods}
\label{penalty}
A constrained optimization problems of the form (\ref{eq:constr})
can be recast as an unconstrained problem by introducing a positive penalty function $\pi$ as follows
\bq
\label{eq:penalty}
\min_{\mbf{m},\mbf{u}} \Phi_{\lambda} = \ts{\frac{1}{2}}||P^T\mathbf{u} - \mathbf{d}||_2^2 + \lambda\pi(\mbf{A}(\mbf{m})\mbf{u} - \mbf{q}).
\eq
The idea is that any departure from the constraint is penalized so that the solution of this 
unconstrained problem will coincide with that of the constrained problem when $\lambda$ is large enough.

\subsection{Quadratic penalty function}
A quadratic penalty function $\pi(\cdot) = \ts{\frac{1}{2}}||\cdot||_2^2$ leads to a differentiable 
unconstrained optimization problem (\ref{eq:penalty}) whose minimizer $\{\overline{\mbf{m}}_{\lambda},\overline{\mbf{u}}_{\lambda}\}$ coincides with the solution
of the constrained optimization problem (\ref{eq:constr}) when $\lambda \uparrow \infty$ \cite[Thm. 17.1]{Nocedal}. 
Practical algorithms rely on repeatedly solving the unconstrained problem for increasing values of $\lambda$.
A common concern with this approach is that the Hessian may become increasingly ill-conditioned 
for large values of $\lambda$ when there are fewer constraints than variables. For PDE-constrained 
optimziation problems in inverse problems, there are typically enough constraints to prevent this and we will
discuss this in more detail in section \ref{algorithm}.

\subsection{Exact penalty methods}
For certain non-smooth penalty functions, such as $\pi(\cdot) = ||\cdot||_1$, the minimizer of $\phi_{\lambda}$
is a solution of the constrained problem for \emph{any} $\lambda \geq \bar{\lambda}$ for some $\bar{\lambda}$
\cite[Thm. 17.3]{Nocedal}. In practice, a continuation
strategy is used to find a suitable value for $\lambda$. An advantage of this approach is that $\lambda$ does
not become arbritarily large and this this avoids the ill-conditioning problems mentioned above. A disadvantage
is that the resulting unconstrained problem is no longer differentiable. 
With large-scale applications in mind, we do not consider exact penalty methods any further in this paper.

\section{A reduced penalty method}
\label{varpro}
Using a quadratic penalty function, the constrained problem (\ref{eq:constr}) is reformulated as

\bq
\label{eq:penalty}
\min_{\mbf{m},\mbf{u}} \mcl{P}(\mbf{m},\mbf{u}) = \ts{\frac{1}{2}}||P^T\mathbf{u} - \mathbf{d}||_2^2 + \ts{\frac{1}{2}}\lambda||A(\mbf{m})\mbf{u} - \mbf{q}||_2^2.
\eq
The gradient and Hessian are given by
\bq
\left(\begin{array}{c}
\mcl{P}_{\mbf{m}}\\
\mcl{P}_{\mbf{u}}\\
\end{array}
\right)
= 
\left(\begin{array}{c}
\lambda G(\mbf{m},\mbf{u})^T\left(A(\mbf{m})\mbf{u} - \mbf{q}\right)\\
P(P^T\mbf{u} - \mbf{d}) + \lambda A(\mbf{m})^T(A(\mbf{m})\mbf{u} - \mbf{d})\\
\end{array}
\right),
\eq
and
\bq
\nabla^2\mcl{P} &=&
\left(
\begin{array}{cc}
\mcl{P}_{\mbf{m},\mbf{m}}&\mcl{P}_{\mbf{m},\mbf{u}}\\
\mcl{P}_{\mbf{u},\mbf{m}}&\mcl{P}_{\mbf{u},\mbf{u}}\\
\end{array}
\right),
\eq
where
\bq
\mcl{P}_{\mbf{m},\mbf{m}} &=& \lambda (G(\mbf{m},\mbf{u})^TG(\mbf{m},\mbf{u}) + R(\mbf{m},\mbf{u},A(\mbf{m})\mbf{u}-\mbf{q})),\\
\mcl{P}_{\mbf{u},\mbf{u}} &=&PP^T + \lambda A(\mbf{m})^TA(\mbf{m}),\\
\mcl{P}_{\mbf{m},\mbf{u}} &=&\lambda (K(\mbf{m},A(\mbf{m})\mbf{u}) + A(\mbf{m})^TG(\mbf{m},\mbf{u})).\\
\eq
Of course, optimization in the full $(\mbf{m},\mbf{u})$-space is not feasible for large-scale problems, so we 
eliminate $\mbf{u}$ using a \emph{variational projection} approach \cite{Aravkin2012c} to define a reduced problem:
\bq
\label{eq:redpenalty}
\min_{\mbf{m}} \phi_{\lambda}(\mbf{m}) = \mcl{P}(\mbf{m},\mbf{u}_{\lambda}(\mbf{m})),
\eq
where $\mbf{u}_{\lambda}(\mbf{m}) = \argmin_{\mbf{u}} \mcl{P}(\mbf{m},\mbf{u})$.
It is readily verified that the gradient and Hessian of $\phi_{\lambda}$ are given by 
\bq
\label{eq:gradpen}
\nabla\phi_{\lambda}(\mbf{m}) &=& \mcl{P}_{\mbf{m}}(\mbf{m},\overline{\mbf{u}}_{\lambda}),\\
\label{eq:hesspen}
\nabla^2\phi_{\lambda}(\mbf{m}) &=& \mcl{P}_{\mbf{m}}^2\Phi_{\lambda}(\mbf{m},\overline{\mbf{u}}_{\lambda}) \nonumber\\
&&-\nabla_{\mbf{m},\mbf{u}}^2\Phi_{\lambda}(\mbf{m},\overline{\mbf{u}}_{\lambda})\left(\nabla_{\mbf{u}}^2\Phi_{\lambda}(\mbf{m},\overline{\mbf{u}}_{\lambda})\right)^{-1}\nabla_{\mbf{u},\mbf{m}}^2\Phi_{\lambda}(\mbf{m},\overline{\mbf{u}}_{\lambda}).
\eq
Note that $\nabla^2\phi_{\lambda}$ is the Schur complement of $\nabla^2\mcl{P}$.

The optimization problem for $\mbf{u}_{\lambda}$ has a closed-form solution and 
the basic Gauss-Newton algorithm for minimizing $\phi_{\lambda}$ is shown in Algorithm \ref{alg:penalty}.

\begin{algorithm}
\caption{Basic Gauss-Newton algorithm for find a stationary point of the Lagrangian via the penalty method}
\label{alg:penalty}
\begin{algorithmic}
\REQUIRE{initial guess $\mbf{m}^0$, penalty parameter $\lambda$, tolerance $\epsilon$}
\STATE{$k=0$}
\REPEAT
\STATE{$\mathbf{u}^k_{\lambda}  = \left(A^TA + \lambda^{-1}PP^T\right)^{-1}\left(A^*\mbf{q} + \lambda^{-1}P^*\mbf{d}\right)$}
\STATE{$\mathbf{v}^k_{\lambda}  = \lambda(A(\mathbf{m}^k)\mathbf{u}^k_{\lambda} - \mathbf{q})$}
\STATE{$\mathbf{g}^k_{\lambda}  = G(\mathbf{m}^k,\mathbf{u}^k_{\lambda})^*\mathbf{v}^k_{\lambda}$}
\STATE{$H^k_{\lambda}           = \lambda G^T\left(I - A\left(A^TA + \lambda^{-1}PP^T\right)^{-1}A^T \right)G$}
\STATE{$\mathbf{m}^{k+1}        = \mathbf{m}^k - \alpha^k \left(H_{\lambda}^{k}\right)^{-1}\mathbf{g}^k_{\lambda}$}
\UNTIL{$\|\mbf{g}_{\lambda}^k\|_2 \leq \epsilon$}
\end{algorithmic}
\end{algorithm}

Note that the modified system $A^*A + \lambda^{-1}PP^T$ is a low-rank update of the original PDE and
incorporates the measurements in the PDE solve. This is the main difference with the conventional reduced approach (cf. Algorithm \ref{alg:reduced}); 
the estimate of the field is not only based on the physics and the current model, but also on the data.

Next, we show how the states generated by this algorithm $\mathbf{u}^k_{\lambda}$ and $\mathbf{v}^k_{\lambda}$ 
relate to the states generated by the reduced approach and subsequently if the algorithm successfully terminates
the iterates satisfy $\|\nabla\mcl{L}\|_2^2 \leq \epsilon + \mcl{O}(\lambda^{-1})$.

\begin{lemma}
For a fixed $\mbf{m}$, the states $\mathbf{u}_{\lambda}$ and $\mathbf{v}_{\lambda}$ used 
in the reduced penalty approach (cf. Algorithm \ref{alg:penalty}) are related to the states $\mathbf{u}_{\mathrm{red}}$ and 
$\mathbf{v}_{\mathrm{red}}$ used in the reduced approach  (cf. Algorithm \ref{alg:reduced})
as follows
\bq
\mathbf{u}_{\lambda} = \mathbf{u}_{\mathrm{red}} + \mcl{O}(\lambda^{-1}),\\
\mathbf{v}_{\lambda} = \mathbf{v}_{\mathrm{red}} + \mcl{O}(\lambda^{-1}).
\eq
\end{lemma}
\begin{proof}
The state variables used in the penalty approach are given by
\[
\mbf{u}_{\lambda} = \left(A^TA + \lambda^{-1}PP^T\right)^{-1}\left(A^T\mbf{q} + \lambda^{-1}P^T\mbf{d}\right),
\]
and
\[
\mbf{v}_{\lambda} = \lambda(A\mbf{u}_{\lambda} - \mathbf{q}).
\]
The former can be re-written as
\[
\mbf{u}_{\lambda} = A^{-1}\left(I + \lambda^{-1}A^{-T}PP^TA^{-1}\right)^{-1}\left(\mbf{q} + \lambda^{-1}A^{-T}P\mbf{d}\right).
\]
For $\lambda > \sigma_{\max}(P^TA^{-1})$, we may expand the inverse as $(I + \lambda^{-1}B)^{-1} \approx I - \lambda^{-1}B + \lambda^{-2}B^2 + \ldots$
and find that
\bq
\mbf{u}_{\lambda} &=& A^{-1}\mbf{q}\nonumber\\
&&+ \lambda^{-1}\left(A^{T}A\right)^{-1}P\left(\mbf{d} - P^TA^{-1}\mbf{q}\right)\nonumber\\
&&- \lambda^{-2}\left(A^{T}A\right)^{-1}PP^T\left(A^{T}A\right)^{-1}P\mbf{d} + \mcl{O}(\lambda^{-3})\nonumber\\
&=& \mbf{u}_{\mathrm{red}} + \lambda^{-1}A\mbf{v}_{\mathrm{red}} + \lambda^{-2}.
\eq
We immediately find
\bq
\mbf{v}_{\lambda} = \mbf{v}_{\mathrm{red}} + \mcl{O}(\lambda^{-1}).
\eq
\end{proof}


\begin{theorem}
At each iteration of algorithm \ref{alg:reduced}, the iterates satisfy 
$\mcl{L}_{\mbf{u}}(\mbf{m}^k,\mbf{u}^k_{\lambda},\mbf{v}^k_{\lambda}) = \mcl{O}(\lambda^{-1})$ and 
$\mcl{L}_{\mbf{v}}(\mbf{m}^k,\mbf{u}^k_{\lambda},\mbf{v}^k_{\lambda}) = 0$
Moreover, if algorithm \ref{alg:reduced} successfully terminates with $\mbf{m}^*$
for which $\|\mbf{g}_{\lambda}^*\|_2 \leq \epsilon$
we have $\|\mcl{L}_{\mbf{m}}(\mbf{m}^*,\mbf{u}^*_{\lambda},\mbf{v}^*_{\lambda})\|_2 \leq \epsilon3$.
\end{theorem}
\begin{proof}
Using the definitions of $\mbf{u}_{\lambda}$ and $\mbf{v}_{\lambda}$ we find
for any $\mbf{m}_{\lambda}$
\bq
\mcl{L}_{\mathbf{u}}(\mbf{m},\mbf{u}_{\lambda},\mbf{v}_{\lambda}) &=& A(\mbf{m})^T\mbf{v}_{\lambda} + P(P^T\mbf{u}_{\lambda} - \mbf{d})\nonumber\\
&=& \lambda A^T(A\mbf{u}_{\lambda} - \mbf{q}) + P(P^T\mbf{u}_{\lambda} - \mbf{d}) = 0.
\eq
Using the approximations for $\mbf{u}_{\lambda}$ and $\mbf{v}_{\lambda}$ for $\lambda>\sigma_{\max}(P^TA)$ presented in Lemma , we find
\bq
\mcl{L}_{\mathbf{v}}(\mbf{m},\mbf{u}_{\lambda},\mbf{v}_{\lambda}) &=& A(\mbf{m})\mbf{u}_{\lambda} - \mbf{q}\nonumber\\
&=& \lambda^{-1}A(\mbf{m})^{-T}P\left(\mbf{d} - P^TA(\mbf{m})^{-1}\mbf{q}\right) + \mcl{O}(\lambda^{-2}).
\eq
At a stationary point $\mbf{m}^*$, $\|\mbf{d} - P^TA(\mbf{m}^*)^{-1}\mbf{q}\|_2$ can be interpreted as the noise level.
Thus we find
\bq
\|\mcl{L}_{\mathbf{v}}(\mbf{m}^*,\mbf{u}^*_{\lambda},\mbf{v}^*_{\lambda})\|_2 \leq \lambda^{-1}\mu\sigma,
\eq
where $\sigma$ is the noise level and $\mu$ is the largest singular value of $P^TA(\mbf{m}^*)^{-1}$.

At a point $\mbf{m}^*$ for which 
$\|\nabla\phi_{\lambda}(\mbf{m}^*)\|_2 \leq \epsilon$
we immediately find that
\bq
\|\mcl{L}_{\mathbf{m}}(\mbf{m}^*,\mbf{u}^*_{\lambda},\mbf{v}^*_{\lambda})\|_2^2 \leq \epsilon.
\eq

Finally, we find that 
\bq
\|\nabla\mcl{L}(\mbf{m}^*,\mbf{u}^*_{\lambda},\mbf{v}^*_{\lambda})\|_2\leq \sqrt{\epsilon^2 + \lambda^{-2}\mu^2\sigma^2}.e
\eq
\qed
\end{proof}

%\section{Analysis of a toy problem}
%\label{toy}
%Before describing algorithms to minimize $\phi_{\mathrm{pen}}$, we will illustrate the potential benefits
%of the penalty approach over the conventional reduced approach with the help of a toy problem with
%\[
%A(\mbf{m}) = 
%\left(\begin{array}{cc}
%\frac{1}{2}&\frac{1}{4}\\
%\frac{1}{4}&1\\
%\end{array}\right),\quad
%q = \left(\begin{array}{c}
%1\frac{3}{4}\\
%2\frac{1}{4}\\
%\end{array}\right).
%\]
%The solution in this case is $\overline{m} = (1,1)$ and $\overline{u} =
%(1,1)$. We use a Gauss-Newton method to solve both (\ref{eq:redL}) and (\ref{eq:redP}), starting from $m = (2,2)$. We use $\lambda = 0.1$ for the penalty approach.
%Figure \ref{fig:opt} (a) shows the solution paths and (c) shows the convergence in terms of $||r||_2$ and $||c||_2$ for both the reduced
%(black) and penalty approaches (red). The penalty approach gets very
%close to the optimal solution in one iteration while the reduced
%approach takes a detour because it is forced to satisfy the constraint
%$c(m,u)=0$ at each iteration. Another perspective is offered by plotting the objective functions corresponding to the reduced and penalty approaches as a function of $m$.
%Figure \ref{fig:opt} (c) shows the reduced objective (\ref{eq:redL}) and (d) shows the penalty objective (\ref{eq:redP}). The reduced objective in this case is quite non-linear while the penalty objective is quadratic.
%These plots illustrate that the penalty formulation can indeed lead to an objective function that is much better behaved.

\section{Algorithms}
\label{algorithm}
In this section we discuss some practicalities of the implementation of algorithm \ref{alg:penalty}. 
We slightly elaborate the notation to explicitly 
reveal the multi-experiment structure of the problem. In this case, the data are acquired in a series
of $M$ independent experiments and $\mbf{d} = [\mbf{d}_1; \ldots; \mbf{d}_{M}]$ is a block-vector. We 
partition the states and sources in a simular manner and, since the experiments are independent, 
system matrix $A$ is block-diagonal matrix with blocks $A_i(\mbf{m})$. The matrix $P$ has rank $L$.

\subsection{Solving the augmented PDE}
Due to the block structure of the problem, the linear systems can be solved independently.
We assume for the moment that the state vector for a single experiment can be held in memory.

We can obtain the states by solving the following inconsistent overdetermined system
\bq
\label{eq:u_pen}
\left(
\begin{array}{c}
A_i(\mbf{m})\\
\lambda^{-1/2}P
\end{array}
\right)
\mbf{u}_{i} \approx
\left(
\begin{array}{c}
\mbf{q}_{i}\\
\lambda^{-1/2}\mbf{d}_{i}
\end{array}
\right),
\eq
in a least-squares sense. If both $A_i$ and $P$ are sparse, we can efficiently solve 
this via a QR factorization or via a Cholesky factorization of the corresponding Normal equations.
For simple measurements, $PP^T$ is a diagonal matrix with ones and zeros and thus the augmented system
$A^TA + \lambda^{-1}PP^T$ has the same sparsity pattern as the original system. 

While we can make use of factorization techniques for
small-scale applications, industry-scale applications will typically
require (preconditioned) iterative solution of such systems. This allows
for on-the-fly generation of the system-matrix, but still requires
the state vector to fit in memory.
It seems most attractive
to work on the overdetermined system directly, rather than form the Normal equations.
Obvious candidates are LSQR or LSMR \cite{Paige1982,Fong2011}.
Another promising
candidate is a generic accelerated row-projected method described by
\cite{Bjorck1979,Gordon2013} which proved successful in seismic
applications and can be easily extended to deal with overdetermined
systems \cite{Censor1983}. 

The augmented system $A^TA + \lambda^{-1} PP^*$ is a rank $L$ modification of the 
original system $A^TA$. It follows from \cite[Thm 8.1.8]{Golub1996} that the eigenvalues are related as
\[
\mu_n(A^TA + \lambda^{-1} PP^T) = \mu_n(A^TA) + a_n \lambda^{-1},
\]
where $\mu_n(B)$ denotes the $n$-th eigenvalue of $B$ and $\sum_n a_n = L$. 


When the state vector does not fit in memory, it is not so obvious how the overdetermined system should
be solved. An example is explicit time-stepping, where the system matrix exhibits a lower-triangular block-structure.

\subsection{Gradient and Hessian}
Given these solutions $\mbf{u}_i$, the gradient, $\mbf{g}_{\lambda}$ and Gauss-Newton Hessian $H_{\lambda}$ of $\phi_{\lambda}$ 
are given by (cf eq. \ref{eq:gradpen}-\ref{eq:hesspen})
\bq
\mbf{g}_{\lambda} &=& \lambda\sum_{i=1}^M G_i^T\left(A_i\mathbf{u}_{i} - \mathbf{q}_{i}\right),\\
H_{\lambda} &=& \lambda\sum_{i=1}^M G_i^T\left(I - A_i\left(A_i^TA_i + \lambda^{-1}PP^T\right)^{-1}A_i^T \right)G_i,
\eq
where $G_i = G(\mbf{m},\mbf{u}_i)$. We can compute the inverse of $\left(A_i^TA_i + \lambda^{-1}PP^T\right)$
in the same way as used when solving for the states. In practice, we would solve for one state at a time and aggregate the 
gradient on the fly. The Hessian is never formed explicitly, but its action is computed as required.
 
\subsection{Complexity estimates}
Assuming we can solve the overdetermined system (\ref{eq:u_pen}) as efficiently as
the original PDE, the evaluation of the gradient requires a factor of 2 less
computation and storage as the gradient in the reduced approach. 
A summary of the leading order computational costs of the penalty, reduced and all-at-once approaches is given in table \ref{table:costs}.

\section{Case studies}
\label{examples}
The following experiments are done in Matlab, using \texttt{slash} to solve the PDEs. We consider both
a Gauss-Newton (GN) and a Quasi-Newton (QN) variant of the algorithms and use a weak Wolfe linesearch
to determine the steplength. In the GN method the Hessian is inverted using 
conjugate gradients (\texttt{pcg}) up to a relative tolerance of $\eta$. The matrix-vector products are computed on the fly.
For the QN method we use the L-BFGS inverse Hessian with a history size of $K$. Finally, we add a regularization term
$\frac{\alpha}{2} \|D\mbf{m}\|_2^2$, where $D$ is the first-order finite-difference matrix,  to both the reduced and penalty approaches. 
We measure the cost of the inversion by counting the number of PDE solves as outlined in table \ref{table:costs}.

The code used to perform the experiments is available from \url{github}.

\subsection{1D DC resistivity}
\bq
\partial_t u = \partial_x(m\partial_x u).
\eq
A discretization in the temporal Fourier domain gives
\bq
A(\mbf{m}) = \imath\omega I + D^T\mathsf{diag}(\mbf{m})D,
\eq
where $\omega$ is the angular frequency and $D$ is the first-order finite-difference matrix. 
We take measurements as follows
\bq
\mbf{d} = \mbf{p}^TA(\mbf{m})^{-1}\mbf{q}.
\eq
The Jacobian is given by $G(\mbf{m},\mbf{u}) = D^T\mathsf{diag}(D\mbf{u})$. 

%We investigate the sensitivity of $\mbf{d}$ w.r.t. a perturbation of a single parameter.
%\bq
%A(\mbf{m} + \delta \mbf{e}_i) = A(\mbf{m}) + \delta \mbf{s}_i\mbf{s}_i^T,
%\eq
%where $\mbf{s}_i$ is the $i$th column of $D$. Using the identity 
%$(A + \mbf{b}\mbf{c}^T)^{-1} = A^{-1} + \frac{1}{1 + \mbf{c}^TA^{-1}\mbf{d}}A^{-1}\mbf{b}\mbf{c}^TA^{-1}$ we find
%\bq
%A(\mbf{m} + \delta \mbf{e}_i)^{-1} = A(\mbf{m})^{-1} + \frac{\delta}{1 + \delta\mbf{s}_i^TA(\mbf{m})^{-1}\mbf{s}_i}A(\mbf{m})^{-1}\mbf{s}_i\mbf{s}_i^TA(\mbf{m})^{-1}.
%\eq
%
%For the reduced approach the objective function is given by 
%\bq
%\phi(\mbf{m}) = \left(\mbf{p}^T(A(\mbf{m})^{-1} - A(\mbf{m^*})^{-1})\mbf{q}\right)^2.
%\eq
%And we find
%\bq
%\phi(\mbf{m}^* + \delta\mbf{e}_i) = \frac{\delta^2}{(1 + \delta\mbf{s}_i^TA(\mbf{m}^*)^{-1}\mbf{s}_i)^2}\left(\mbf{p}^T(A(\mbf{m}^*)^{-1}\mbf{s}_i\mbf{s}_i^TA(\mbf{m}^*)^{-1})\mbf{q}\right)^2
%\eq
%For the penalty approach we have
%\bq
%\phi_{\lambda}(\mbf{m}) = \left(\mbf{p}^T(\mbf{u}_{\lambda} - A(\mbf{m^*})^{-1}\mbf{q})\right)^2 + \lambda\|A(\mbf{m})\mbf{u}_{\lambda} - \mbf{q}\|^2
%\eq

\subsection{2D seismic waveform inversion}
Consider the 2D scalar wave-equation
\bq
\left(m\partial_t^2 - \nabla^2\right)u = 0
\eq
with radiation boundary conditions $\sqrt{m}\partial_t - \partial_n u = 0$.
Discretization in the temporal Fourier domain leads to
\bq
A(\mbf{m}) = \mathsf{diag}(\mbf{a})\mathsf{diag}(\mbf{m}) + D^TD,
\eq
where $a_i = \omega^2$ in the interior and $a_i = $ on the boundary.
The Jacobian is given by
\bq
G(\mbf{m},\mbf{u}) = \mathsf{diag}(\mbf{a})\mathsf{diag}(\mbf{u}).
\eq

\section{Discussion}
\label{discussion}
This paper lays out the basics of an efficient implementation of the
penalty method for PDE-constrained optimization. A few remaining issues
and possible extensions are listed below.
%\begin{description}
%\item[Time-domain formulation]
%We have described application of the penalty method to a formulation in
%the frequency domain, in which case we can hope to store a complete
%wavefield $\mathbf{u}_{kl}$ for one source and frequency. In a
%time-domain formulation, the PDE (after spatial discretization) can be
%written as
% \[
% M(\mathbf{m})\mbf{u}'(t) + S\mathbf{u}(t) = \mathbf{q}(t),
% \]
%which can be solved via some form of time-stepping. The augmented
%wave-equation involves an extra equation of the form $P\mathbf{u}(t) =
%\mbf{d}(t)$. While we can in principle form a large overdetermined system
%for the wavefield at all timesteps, this is not feasible and a suitable
%time-stepping strategy will have to be developed to solve the augmented
%PDE without storing the wavefields for all timesteps.

%\item[Other PDE-constrained optimization problems]
%The penalty formulation can be applied to any PDE-constrained
%optimization problem. We can only expect an efficient implementation
%along the lines described in this paper, however, if the PDE is linear
%in the state variable. In particular, application to multi-parameter
%seismic inversion (e.g., visco-acoustic, variable density,
%visco-elastic) is straightfoward.
%
%\item[Dimensionality reduction]
%The computational cost may be reduced by using recently proposed
%dimensionality reduction techniques that essentially reduce the number
%of right-hand-sides of the PDE by random subselection or aggregration
%\cite{Haber2012,Friedlander2012,VanLeeuwen2012b}. These techniques can
%be directly included in the penalty formulation by introducing new
%sources and their corresponding data;
%\[
%\widetilde{\mbf{q}}_{kl'} = \sum_{l}w_{ll'}\mbf{q}_{kl}, \quad \widetilde{\mbf{d}}_{kl'} = \sum_{l}w_{ll'}\mbf{d}_{kl},
%\]
%where $l' = [1,2,\ldots,N_s']$ ($N_s' << N_s$) and $w_{l'l}$ are
%suitably chosen random weights.
%
%\item[Regularization] 
%Regularization penalties on the model $\mathbf{m}$ can be included in
%a trivial manner. Also, regularization techniques on the (Gauss-Newton)
%subproblems can be included. This includes for example $\ell_1$
%regularization as proposed by \cite{Li2012} and $\ell_2$ regularization
%as is used in trust-region methods. 
%
%\item[Penalties] 
%Penalties other than the $\ell_2$ norm on either the data-misfit or the
%constraint can be included in the formulation (\ref{eq:penalty}).
%However, this will most likely prevent us from solving for the
%wavefields efficiently via system of equations (\ref{eq:u_pen}). Still,
%most alternative penalties may be approximated by a weighted $\ell_2$
%norm, in which case a system like (\ref{eq:u_pen}) \emph{can} be formed 
%and solved via an iteratively re-weighted least-squares approach \cite{Bjorck1979}.
%
%\item[Nuisance parameters] 
%Formulations of the inverse problem may include additional
%parameters that need to be estimated. An example of this are the
%source-weights in the seismic applications. The penalty objective, in
%this case becomes
%\[
%\phi_{\lambda}(\mathbf{m},\mathbf{u},\theta) = \ts{\frac{1}{2}}\sum_{k,l}||\theta_{kl}P \mbf{u}_{kl} - \mbf{d}_{kl}||_2^2 + \lambda^2||\theta_{kl}A_k(\mbf{m})\mbf{u}_{kl} - \mbf{q}_{kl}||_2^2,
%\]
%The wavefield may be solved first from (\ref{eq:u_pen}) and subsequent
%minimization over $\theta$ for the given wavefields is trivial as a
%closed-form solution is available:
%\[
%\theta_{kl} = \frac{\mbf{u}_{kl}^*\left(P^*\mbf{d}_{kl} + \lambda^2A_k^*\mbf{q}_{kl}\right)}{||P\mbf{u}_{kl}||_2^2 + \lambda^2 ||A_k\mbf{u}_{kl}||_2^2}.
%\]
%
%This approach can be generalized to more complicated situations in which
%a closed-form solution is not available \cite{Aravkin2012c}.
%
%\item[Contination strategies for $\lambda$] 
%The experiments presented in this paper were done for a fixed value of
%$\lambda$. To ensure that one really solves the original constrained
%problem, however, a suitable strategy for increasing $\lambda$ needs to
%be developed.
%
%\item[Optimization strategies]
%In this paper we described a Gauss-Newton method to minimize the reduced
%penalty objective (\ref{eq:redpenalty}). Using the expressions for the gradient and Hessian presented in section 3.1, we can design other Newton variants. 
%
%Recently proposed stochastic algorithms aimed at dramatically reducing the cost of PDE-constrained optimization problems by working on a small subsets of the right-hand-sides \cite{Krebs09,Friedlander2012,Haber12,VanLeeuwen2012b} are directly applicable to this formulation.
%\end{description}

\section{Conclusions}
\label{conclusion}
We have presented a new method for PDE-constrained optimization based on
a penalty formulation of the constrained problem. The method
relies on solving for the state variables from an augmented system that
is comprised of the original discretized PDE and the measurements. The
resulting estimates of the state variables can be used to directly
estimate the control variable from the PDE via an equation-error
approach. The main benefits of this method are: \emph{i)} The state
variables for each experiment can be obtained independently and do not
have to be stored or updated as part of an iterative optimization
procedure, \emph{ii)} the penalty formulation leads to a less non-linear
formulation than the reduced approach where the PDE-constraint is
eliminated explicitly, and \emph{iii)} the gradient of the objective
with respect to the control variable can be computed directly from the
state variables, without the need to solve adjoint PDEs. We illustrate
the approach on a non-linear seismic inverse problem, showing that the
reduced non-linearity leads to significantly better results than the
reduced approach at roughly half the computational costs (due to the
fact that there is no adjoint equation to solve). Moreover, the penalty
approach succesfully mitigates some of the the issues with local minima
making the procedure less sensitive to the initial model.

\section*{Acknowledgments}
The authors wish to thank Dan and Rachel Gordon for valuable discussions
on the CARP-CG method. This work was in part financially supported by
the Natural Sciences and Engineering Research Council of Canada
Discovery Grant (22R81254) and the Collaborative Research and
Development Grant DNOISE II (375142-08). This research was carried out
as part of the SINBAD II project with support from the following
organizations: BG Group, BGP, BP, Chevron, CGG, ConocoPhillips, ION,
Petrobras, PGS, Total SA, WesternGeco and Woodside.


\clearpage

\begin{table}
\begin{tabular}{c|c|c|p{5cm}}
         & \# PDE's & Storage & Gauss-Newton update \\
\hline
penalty  &  $M$  &    $N$     & solve matrix-free linear system in $N$ unknowns, requires $M$ (overdetermined) PDE solves per mat-vec \\
\hline
reduced  &  $2M $  &    $2N$     & solve matrix-free linear system in $N$ unknowns, requires $2M$ PDE solves per mat-vec                   \\
\hline
all-at-once&   0   &    $(M+1) \times N$   &  solve sparse symmetric, possibly indefinite system in $(M + 1) \times N3$ unknowns \\ 
\end{tabular}
\caption{Leading order computation and storage costs per iteration of different methods; $M$ denotes the number of experiments and $N$ denotes the number of gridpoints.
for large-scale 3D seismic inverse problems we typically have $M = \mcl{O}(10^6)$ and $N = \mcl{O}(10^9)$.}
\label{table:costs}
\end{table}
\clearpage

\begin{algorithm}
\caption{Gauss-Newton algorithm based on the penalty formulation}
\label{GN1}
\begin{algorithmic}
\FOR{$t = 0$ to $N$}
\STATE $\mbf{g}_t = 0$
\STATE $H_t = 0$
\FOR{$k = 1$ to $N_f$}

\FOR{$l = 1$ to $N_s$}
\STATE solve $\left(\begin{array}{c} \lambda_t A_k(\mbf{m}_t) \\ P \end{array}\right)\mbf{u}_{kl} = \left(\begin{array}{c}\lambda_t\mbf{q}_{kl}\\ \mbf{d}_{kl} \end{array}\right)$
\STATE $\mbf{g}_t = \mbf{g}_t  + \lambda_t^2G_k(\mbf{m}_t, \mbf{u}_{kl})^*(A_k(\mbf{m}_t)\mbf{u}_{kl} - \mbf{q}_{kl})$
\STATE $H_t = H_t + (\lambda_t^2 - 1)G_k(\mbf{m}_t, \mbf{u}_{kl})^*G_k(\mbf{m}_t, \mbf{u}_{kl})$
\ENDFOR


\ENDFOR

\STATE solve $H_t\Delta \mbf{m}_t = -\mbf{g}_t$
\STATE update $\mbf{m}_{t+1} = \mbf{m}_t + \Delta \mbf{m}_t$
\STATE update $\lambda_t$.
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Quasi-Newton algorithm based on the reduced formulation}
\label{QN2}
\begin{algorithmic}
\FOR{$t = 0$ to $N$}
\STATE $\mbf{g}_t = 0$
\FOR{$k = 1$ to $N_f$}

\FOR{$l = 1$ to $N_s$}
\STATE solve $A_k(\mbf{m}_t)\mbf{u}_{kl} =\mbf{q}_{kl}$
\STATE solve $A_k(\mbf{m}_t)^*\mbf{v}_{kl} = -P^*(P\mbf{u}_{kl} - \mbf{d}_{kl})$
\STATE $\mbf{g}_t = \mbf{g}_t  + G_k(\mbf{m}_t, \mbf{u}_{kl})^*\mbf{v}_{kl}$
\ENDFOR

\ENDFOR

\STATE apply L-BFGS Hessian $\Delta \mbf{m}_t = \msf{lbfgs}(-\mbf{g}_t,\{\mbf{m}_{t-M}, \ldots, \mbf{m}_t\},\{\mbf{g}_{t-M}, \ldots, \mbf{g}_t\})$
\STATE find a suitable steplength $\alpha$ 
\STATE update $\mbf{m}_{t+1} = \mbf{m}_t + \alpha\Delta \mbf{m}_t$
\ENDFOR
\end{algorithmic}
\end{algorithm}


\clearpage

\begin{figure}
\centering
\begin{tabular}{cc}
\includegraphics[scale=.4]{./figs/opt_b}&
\includegraphics[scale=.4]{./figs/opt_c}\\
{\small (a)}&{\small (b)}\\
\includegraphics[scale=.4]{./figs/opt_d}&
\includegraphics[scale=.4]{./figs/opt_e}\\
{\small (c)}&{\small (d)}\\
\end{tabular}
\caption{Illustration of the reduced and penalty approach on a simple 4 dimensional test problem. (a) Solution paths and (b) the convergence in terms of $||r||_2$ and $||c||_2$ for both the reduced (black) and penalty approaches (red). The objective functions corresponding to the reduced and penalty approaches are shown in (c) and (d) respectively.}
\label{fig:opt}
\end{figure}



\clearpage
\bibliographystyle{unsrt}
\bibliography{mybib}



\end{document}

